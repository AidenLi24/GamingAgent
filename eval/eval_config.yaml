# Configuration for the evaluation script (eval.py)

# List of game names to process
# Example: ["twenty_forty_eight", "Sokoban"]
game_list: ["twenty_forty_eight"]

# List of model names/prefixes to process
# Example: ["claude-3-5-sonnet-20241022", "gpt-4o"]
model_list: ["claude-3-5-sonnet-20241022"]

# Force update existing entries in model_perf_rank.json (boolean)
force_model_perf_rank: false

# Force update existing entries in game_perf.json (boolean)
force_game_perf: false

# Generate bar plot (boolean)
generate_bar_plot: true

# Generate radar chart (boolean)
generate_radar_chart: true

# Generate video replays for supported games (boolean)
# Currently supports "twenty_forty_eight" median score replay from game_perf.json step_infos.
generate_replays: true